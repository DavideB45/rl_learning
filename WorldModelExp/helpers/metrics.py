import torch
import torch.nn.functional as F
from torch import Tensor

import os
import sys
sys.path.insert(1, os.path.join(sys.path[0], '../'))
from vae.vqVae import VQVAE

def weighted_mse(x:Tensor, y:Tensor, error_decay:float=0.9) -> Tensor:
		'''
		Compute the mean square error for each time step and weight it by the decay factor
		To know more see Robotic World Model paper

		:param x: the generated sequence
		:type x: Tensor
		:param y: the original sequence
		:type y: Tensor
		:param error_decay: the decay factor for the loss
		:type error_decay: float
		:return: the computed error
		:rtype: Tensor
		'''
		mse_per_timestep = ((x - y) ** 2).mean(dim=(2,3,4))
		weights = error_decay ** torch.arange(1, mse_per_timestep.size(1) + 1, device=y.device)
		loss = (mse_per_timestep * weights).mean()
		return loss

def weighted_ce(x:torch.Tensor, target:torch.Tensor, w_h:int, classes:int, error_decay:float=0.9) -> torch.Tensor:
		'''
		Compute the cross entropy error for each time step and weight it by the decay factor
		
		:param x: the generated sequence (Batch, Seq_len, Width*Height*Classes)
		:type x: torch.Tensor
		:param target: the original sequence (Batch, Seq_len, Width*Height*Classes)
		:type target: torch.Tensor
		:param w_h: the width and height of the latent space generated by the vq used
		:type w_h: int
		:param classes: the codebook size of the VQVAE used
		:type classes:
		:param error_decay: the decay factor for the loss
		:type error_decay: float
		:return: the computed error
		:rtype: Tensor
		'''
		b = target.size(0)
		s = target.size(1)
		
		x = x.view(b, s, w_h*w_h, classes)  # (B, S, W*H, C)
		y_indices = torch.argmax(target, dim=-1).view(b, s, w_h*w_h)  # (B, S, W*H)
		x = x.permute(0, 3, 1, 2)  # (B, C, S, W*H) - put classes in dim 1 for cross_entropy
		ce_per_location = F.cross_entropy(x, y_indices, reduction='none')  # (B, S, W*H)
		ce_per_timestep = ce_per_location.mean(dim=-1)  # (B, S) - average over spatial locations
		weights = error_decay ** torch.arange(1, s + 1, device=target.device)  # (S,)
		weighted_loss = (ce_per_timestep * weights.unsqueeze(0)).mean()  # scalar
		
		return weighted_loss

def weighted_categorical_kl(x:torch.Tensor, target:torch.Tensor, w_h:int, classes:int, error_decay:float=0.9) -> torch.Tensor:
		'''
		Compute the kullback leiber divergence between a prediction and a target.
		It assumes that both are categorical distributions. 

		**WARNING:** in a divergence the order is important.
		
		:param x: the generated sequence (Batch, Seq_len, Width*Height*Classes)
		:type x: torch.Tensor
		:param target: the original sequence (Batch, Seq_len, Width*Height*Classes)
		:type target: torch.Tensor
		:param w_h: the width and height of the latent space generated by the vq used
		:type w_h: int
		:param classes: the codebook size of the VQVAE used
		:type classes:
		:param error_decay: the decay factor for the loss
		:type error_decay: float
		:return: the computed error
		:rtype: Tensor
		'''
		b = target.size(0)
		s = target.size(1)
		
		eps = 1e-8
		x = x.view(b, s, w_h*w_h, classes)  # (B, S, W*H, C)
		x = F.softmax(x, -1)
		x = x.clamp(min=eps)
		target = target.clamp(min=eps)

		target = target.view((b, s, w_h*w_h, classes)) # (B, S, W*H, C)
		kl_per_step = (x*torch.log(x/target)).sum(dim=3).mean(dim=2)
		
		weights = error_decay ** torch.arange(1, s + 1, device=target.device)
		weighted_loss = (kl_per_step*weights).mean()
		return weighted_loss

def pred_accuracy(pred:torch.Tensor, target:torch.Tensor, w_h:int, classes:int) -> torch.Tensor:
		'''
		Compute the classification accuracy based on what a vq
		
		:param pred: the generated sequence (Batch, Seq_len, Width*Height*Classes)
		:type pred: torch.Tensor
		:param target: the original sequence (Batch, Seq_len, Width*Height*Classes)
		:type target: torch.Tensor
		:param w_h: the width and height of the latent space generated by the vq used
		:type w_h: int
		:param classes: the codebook size of the VQVAE used
		:type classes:
		:return: the accuracy (fraction of correct predictions)
		:rtype: Tensor
		'''
		b = target.size(0)
		s = target.size(1) # length of the sequence
		
		pred = pred.view(b*s*w_h*w_h, classes)
		target_indices = torch.argmax(target, dim=-1).view(b * s * w_h * w_h)
		pred_indices = torch.argmax(pred, dim=-1)
		
		correct = (pred_indices == target_indices).float()
		accuracy = correct.mean()
		
		return accuracy