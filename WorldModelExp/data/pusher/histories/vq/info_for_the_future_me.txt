in no_smoothings ci sono i test che ho fatto prima di introdurre lo smoothing;
possono essere considerati vecchi dato che non c'è una componente importante
in questi test i valori di ricostruzione potrebbero essere migliori perché per qualche 
misterioso motivo una batch size più piccola migliorava l'errore. in teoria qui si 
tratta semplicemente di cercare lr migliori per gli altri casi ma non mi sembra un 
investimento di risorse sensato

in many ci sono tet generici in cui lo smoothing è messo sempre ad 1 o 0

in smooth_criminal ci sono test fatti per vedere come l'aumento del peso della regolarizzazzione
(smoothing) influisce sulla loss finale. Questo perché nei test precedenti ho notato che
con l'aggiunta della penalizzazione la ricostruzione migliorava
